# 应用服务 WEB 访问端口
server.port=8080


###kafka###
spring.kafka.bootstrap-servers= 124.222.117.4:9092
##producter
# acks = 0 producer不等待服务器反馈，默认服务器已接收到请求
# acks = 1 只等待leader反馈，不等待follower的反馈.如果follower失败则整条数据丢失，默认值为1
# acks = -1/all 等待leader和follower都反馈成功
spring.kafka.producer.acks= all
# 用来缓冲等待被发送到服务器的记录的总字节数s
spring.kafka.producer.buffer-memory= 33554432
# 批处理时是否压缩数据，可选类型none, gzip, snappy, 或者 lz4，默认是none不压缩
spring.kafka.producer.compression-type= gzip
# retry 发送失败后是否重试，默认为0不重试。重试之后发送的顺序可能会发生改变
spring.kafka.producer.retries= 3
# 确保每条消息只会在kafka的partition中写入一次，避免重试导致的消息重复
spring.kafka.producer.properties.enable.idempotence = true
# 事务ID，和上面的enable.idempotence组合使用，缺省将无法使用事务
spring.kafka.producer.properties.transactional.id = test-producer-transactional
# 批处理缓存大小
spring.kafka.producer.batch-size= 16384
# org.apache.kafka.common.serialization.Serializer
spring.kafka.producer.key-serializer= org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer= org.apache.kafka.common.serialization.StringSerializer
# 用于方便服务器日志追踪定位，而不是仅仅根据IP端口进行区分
spring.kafka.producer.client-id= test-producer
# 会将两个请求发送时间间隔内到达的记录合并到一个单独的批处理请求中。用于提高吞吐量，但是响应的也会增加延迟，单位为毫秒
spring.kafka.producer.linger.ms = 5

##consumer
spring.kafka.consumer.client-id= test-consumer
#org.apache.kafka.common.serialization.Deserializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.group-id= test
spring.kafka.consumer.auto-offset-reset=earliest
# 读取已提交的事务消息
spring.kafka.consumer.isolation-level= read_committed
# 关闭自动提交
spring.kafka.consumer.enable-auto-commit=false

##listen

##topic
kafka.topics[0].name= test
kafka.topics[0].partitions=3
kafka.topics[0].replicas= 1
